# 2.3 Linux 系统收包流程以及内核参数优化指南

随着业务规模的发展，大规模的集群服务治理问题已经将 C10K 发展到 C10M（单机并发 1000 万），在本节，我们概览一个 Linux 系统收包的流程，以便了解高并发系统所面临的性能瓶颈问题以及相关的优化策略。

<div  align="center">
	<img src="../assets/networking.svg" width="550"  align=center />
	<p>图 2-5 Linux 系统收包流程概览 </p>
</div>

根据 图 2-5 示例，Linux 系统收包流程如下。

1. 网卡 eth0 收到数据包。
2. 网卡通过 DMA 将数据包拷贝到内存的环形缓冲区(ring buffer)。
3. 数据从网卡拷贝到内存后, 网卡产生 IRQ（Interupt ReQuest，硬件中断）告知内核有新的数据包达到。
4. 内核收到中断后, 调用相应中断处理函数，开始唤醒 ksoftirqd 内核线程处理软中断。
5. 内核进行软中断处理，调用 NAPI poll 接口来获取内存环形缓冲区(ring buffer)的数据包，送至更上层处理。
6. 内核中网络协议栈：L2 处理。
7. 内核中网络协议栈：L3 处理。
8. 内核中网络协议栈：L4 处理。
9. 网络协议栈处理数据后，并将其发送到对应应用的 socket 接收缓冲区。

如果内核支持数据包定向分发(packet steering)或者网卡本身支持多个接收队列的话, 从网卡过来的数据会在不同的 CPU 之间进行均衡, 从而获得更高的网络速率。